{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from IPython.display import display\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The following command must be run outside of the IPython shell:\n",
      "\n",
      "    $ pip install xgboost\n",
      "\n",
      "The Python package manager (pip) can only be used from outside of IPython.\n",
      "Please reissue the `pip` command in a separate terminal or command prompt.\n",
      "\n",
      "See the Python documentation for more information on how to install packages:\n",
      "\n",
      "    https://docs.python.org/3/installing/\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.svm import SVC\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(r'C:\\Users\\mjv33\\Downloads\\bank.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1.2 Peek at the training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        job  marital    education  default housing loan    contact  \\\n",
       "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
       "1   57   services  married  high.school  unknown      no   no  telephone   \n",
       "2   37   services  married  high.school       no     yes   no  telephone   \n",
       "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
       "4   56   services  married  high.school       no      no  yes  telephone   \n",
       "\n",
       "  month day_of_week ...  campaign  pdays  previous     poutcome emp.var.rate  \\\n",
       "0   may         mon ...         1    999         0  nonexistent          1.1   \n",
       "1   may         mon ...         1    999         0  nonexistent          1.1   \n",
       "2   may         mon ...         1    999         0  nonexistent          1.1   \n",
       "3   may         mon ...         1    999         0  nonexistent          1.1   \n",
       "4   may         mon ...         1    999         0  nonexistent          1.1   \n",
       "\n",
       "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
       "0          93.994          -36.4      4.857       5191.0  no  \n",
       "1          93.994          -36.4      4.857       5191.0  no  \n",
       "2          93.994          -36.4      4.857       5191.0  no  \n",
       "3          93.994          -36.4      4.857       5191.0  no  \n",
       "4          93.994          -36.4      4.857       5191.0  no  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'full_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-4cd03cc5b0c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfull_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'full_data' is not defined"
     ]
    }
   ],
   "source": [
    "full_data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The training dataset has\",data.shape[1],\"columns and\", data.shape[0],\"rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Overview of responses and overall response rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate number of customers\n",
    "n_customers = len(data)\n",
    "\n",
    "# Calculate number of features\n",
    "n_features = len(data.columns[:-1])\n",
    "\n",
    "# Calculate reponded customers\n",
    "n_subscribed = len(data[data['y'] == 'yes'])\n",
    "\n",
    "# Calculate not responded customers\n",
    "n_not_subscribed = len(data[data['y'] == 'no'])\n",
    "\n",
    "# Calculate response rate\n",
    "response_rate = n_subscribed/(n_customers)*100\n",
    "\n",
    "# Print the results\n",
    "print(\"Total number of customers: {}\".format(n_customers))\n",
    "print(\"Number of features: {}\".format(n_features))\n",
    "print(\"Number of customers who subscribed: {}\".format(n_subscribed))\n",
    "print(\"Number of customers who did not subscribe: {}\".format(n_not_subscribed))\n",
    "print(\"Response rate of customers: {:.2f}%\".format(response_rate))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(data.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Exploratory Analysis - Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#histogram\n",
    "h = sns.distplot(data['age'], bins=10, kde=False)\n",
    "sns.plt.title('Age distribution in the data')\n",
    "h.figure.set_size_inches(16,6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.5)\n",
    "g = sns.FacetGrid(data, col=\"marital\", col_wrap=2, size=5, aspect=1.5)  \n",
    "g.map(sns.boxplot, \"job\",\"duration\").set_xticklabels(rotation=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.5)\n",
    "g = sns.FacetGrid(full_data, col=\"marital\", col_wrap=2, size=6, aspect=1.5)\n",
    "g.map(sns.distplot, \"age\", bins=10).set_xticklabels(rotation=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed'\n",
    "sns.set(font_scale=1.5)\n",
    "g = sns.pairplot(data[[\"age\", \"duration\", \"marital\", \"campaign\",\"euribor3m\"]], hue=\"marital\", diag_kind=\"hist\", size=4)  \n",
    "for ax in g.axes.flat:  \n",
    "    plt.setp(ax.get_xticklabels(), rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.5)\n",
    "g = sns.PairGrid(data[[\"age\", \"duration\", \"marital\", \"euribor3m\"]], hue=\"marital\", size=5)  \n",
    "g.map_upper(sns.regplot)  \n",
    "g.map_lower(sns.residplot)  \n",
    "g.map_diag(plt.hist)  \n",
    "for ax in g.axes.flat:  \n",
    "    plt.setp(ax.get_xticklabels(), rotation=45)\n",
    "g.add_legend()  \n",
    "g.set(alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.5)\n",
    "g = sns.JointGrid(x=\"campaign\", y=\"duration\", data=data, size=6)  \n",
    "g.plot_joint(sns.regplot, order=2)  \n",
    "g.plot_marginals(sns.distplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visulize correlations of features with a heatmap\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.heatmap(data.corr())\n",
    "plt.xticks(rotation=90)\n",
    "plt.yticks(rotation=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2. Data Preprocessing/Cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2.1 Preprocess Feature Columns\n",
    "In the following section, we will convert columns like profession and marital status to cetegorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_features(X):\n",
    "    ''' Preprocesses the student data and converts non-numeric binary variables into\n",
    "        binary (0/1) variables. Converts categorical variables into dummy variables. '''\n",
    "    \n",
    "    # Initialize new output DataFrame\n",
    "    output = pd.DataFrame(index = X.index)\n",
    "\n",
    "    # Investigate each feature column for the data\n",
    "    for col, col_data in X.iteritems():\n",
    "        \n",
    "        # If data type is non-numeric, replace all yes/no values with 1/0\n",
    "        if col_data.dtype == object:\n",
    "            col_data = col_data.replace(['yes', 'no','unknown'], [1, 0, np.nan])\n",
    "\n",
    "        # If data type is categorical, convert to dummy variables\n",
    "        if col_data.dtype == object:\n",
    "            col_data = pd.get_dummies(col_data, prefix = col)  \n",
    "        \n",
    "        # Collect the revised columns\n",
    "        output = output.join(col_data)\n",
    "    \n",
    "    return output\n",
    "\n",
    "data = preprocess_features(data)\n",
    "print(\"Processed feature columns ({} total features):\\n{}\".format(len(data.columns), list(data.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2.2 Identify feature and target columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature columns\n",
    "feature_cols = list(data.columns[:-1])\n",
    "\n",
    "# Extract target column 'responded'\n",
    "target_col = data.columns[-1] \n",
    "\n",
    "# Show the list of columns\n",
    "print(\"Feature columns:\\n{}\".format(feature_cols))\n",
    "print(\"\\nTarget column: {}\".format(target_col))\n",
    "\n",
    "# Separate the data into feature data and target data (X_all and y_all, respectively)\n",
    "X_all = data[feature_cols]\n",
    "y_all = data[target_col]\n",
    "\n",
    "# Show the feature information by printing the first five rows\n",
    "print(\"\\nFeature values:\")\n",
    "print(X_all.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2.3 Data cleaning/washing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looking at missing values:\n",
    "X_all.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nr.employed as the most missing values and hence we will drop that\n",
    "X_all.drop('nr.employed',  axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all.fillna(X_all.median(), inplace=True)\n",
    "X_all.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Processed feature columns ({} total features):\\n{}\".format(len(X_all.columns), list(X_all.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export cleaned data\n",
    "\n",
    "filename = 'cleaned_X_all.csv'\n",
    "X_all.to_csv(filename, index=False, encoding='utf-8')\n",
    "filename = 'cleaned_y_all.csv'\n",
    "y_all.to_csv(filename, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read cleaned data directly\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series\n",
    "import seaborn as sns\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from IPython.display import display\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "in_file = 'cleaned_X_all.csv'\n",
    "X_all = pd.read_csv(in_file)\n",
    "in_file = 'cleaned_y_all.csv'\n",
    "y_all = pd.read_csv(in_file, squeeze=True, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set 'yes' pct = 11.27%\n",
      "Validation  set 'yes' pct = 11.26%\n",
      "Training set has 28831 samples.\n",
      "Validation set has 12357 samples.\n"
     ]
    }
   ],
   "source": [
    "validation_size = 0.30\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_all, y_all, stratify = y_all, \n",
    "                                                    test_size = validation_size, random_state = 123)\n",
    "print(\"Train set 'yes' pct = {:.2f}%\".format(100 * (y_train == 1).mean()))\n",
    "print(\"Validation  set 'yes' pct = {:.2f}%\".format(100 * (y_validation == 1).mean()))\n",
    "\n",
    "# Show the results of the split\n",
    "print(\"Training set has {} samples.\".format(X_train.shape[0]))\n",
    "print(\"Validation set has {} samples.\".format(X_validation.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWe will use the following algorithms:\\n\\n1) Logistic Regression (LR)\\n2) Classification and Regression Trees (CART)\\n3) Random Forests (RF)\\n4) Adaptive Boosting (AB)\\n5) Extreme Gradient Boosting (XGB)\\n\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Implementing Models:\n",
    "\n",
    "\"\"\"\n",
    "We will use the following algorithms:\n",
    "\n",
    "1) Logistic Regression (LR)\n",
    "2) Classification and Regression Trees (CART)\n",
    "3) Random Forests (RF)\n",
    "4) Adaptive Boosting (AB)\n",
    "5) Extreme Gradient Boosting (XGB)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading https://files.pythonhosted.org/packages/5e/49/b95c037b717b4ceadc76b6e164603471225c27052d1611d5a2e832757945/xgboost-0.90-py2.py3-none-win_amd64.whl (18.3MB)\n",
      "Requirement already satisfied: scipy in c:\\users\\mjv33\\anaconda3\\lib\\site-packages (from xgboost) (1.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\mjv33\\anaconda3\\lib\\site-packages (from xgboost) (1.15.4)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-0.90\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mjv33\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurary of sklearn wrapper:  0.9184268026219956\n",
      "Accuracy of XGBoost library:  0.9117099619648782\n",
      "---------------------------------------------\n",
      "sklearn predictions:  [1 0 0 ... 0 0 0]\n",
      "XGB library predictions:  [1. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Test to check how XGBoost compares with SKLearn wrapper\n",
    "\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "clf = XGBClassifier()\n",
    "param = clf.get_xgb_params()\n",
    "clf.fit(X_train, y_train)\n",
    "preds_sk = clf.predict(X_validation)\n",
    "\n",
    "import xgboost as xgb\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dvalid = xgb.DMatrix(X_validation)\n",
    "bst = xgb.train(param, dtrain)\n",
    "preds = bst.predict(dvalid).round()\n",
    "\n",
    "print(\"Accurary of sklearn wrapper: \",accuracy_score(y_validation, preds_sk))\n",
    "print(\"Accuracy of XGBoost library: \",accuracy_score(y_validation, preds.round()))\n",
    "print(\"---------------------------------------------\")\n",
    "print(\"sklearn predictions: \", preds_sk)\n",
    "print(\"XGB library predictions: \",preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mjv33\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\mjv33\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\mjv33\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\mjv33\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\mjv33\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\mjv33\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\mjv33\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\mjv33\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\mjv33\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\mjv33\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. LR: 0.909681 (0.005114)\n",
      "2. CART: 0.889286 (0.006494)\n",
      "3. RF: 0.912455 (0.007363)\n",
      "4. AB: 0.913704 (0.005999)\n",
      "5. XGB: 0.914640 (0.005547)\n"
     ]
    }
   ],
   "source": [
    "scoring = 'accuracy'\n",
    "\n",
    "#Spot check algorithms\n",
    "models = []\n",
    "models.append(('1. LR', LogisticRegression()))\n",
    "models.append(('2. CART', DecisionTreeClassifier()))\n",
    "models.append(('3. RF', RandomForestClassifier(n_estimators=100)))\n",
    "models.append(('4. AB', AdaBoostClassifier(RandomForestClassifier(n_estimators=100), \n",
    "                                        algorithm='SAMME',n_estimators=100, learning_rate=1.0)))\n",
    "models.append(('5. XGB', XGBClassifier()))\n",
    "# Evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits = 10, random_state = 123)\n",
    "    cv_results = model_selection.cross_val_score(model, X_train, y_train,\n",
    "                                                cv = kfold, \n",
    "                                                 scoring = scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Selecting a best model:\n",
    "\n",
    "\"\"\"\n",
    "We now have 5 models and accuracy estimations for each. We need to compare the models to each other and select the most accurate. The output of above code cell shows XGB being the winner with highest estimated accuracy score.\n",
    "\n",
    "The plot below shows model evaluation results and compare the spread and the mean accuracy of each model. There is a population of accuracy measures for each algorithm beacuse each algortihm was evaluated 10 times (10 fold cross validation)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Compare Algorithms\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Predictions on Validation Set:\n",
    "\n",
    "\n",
    "\n",
    "The XGB model was the most accurate model that we tested. Now we want to get an idea of accuracy of the model on our validation set. This will give us an independent final check on the accuracy of th best model.\n",
    "\n",
    "We can run the XGB model directly on the validation set and summarize the results as a final accuracy score, a confusion matrix and a classification report.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.9184268026219956\n",
      "----------------------------------------------------------\n",
      "Confusion Matrix: \n",
      " [[10615   350]\n",
      " [  658   734]]\n",
      "----------------------------------------------------------\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95     10965\n",
      "           1       0.68      0.53      0.59      1392\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     12357\n",
      "   macro avg       0.81      0.75      0.77     12357\n",
      "weighted avg       0.91      0.92      0.91     12357\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select best model\n",
    "# Make predictions on validation dataset\n",
    "xgb = XGBClassifier()\n",
    "fit = xgb.fit(X_train, y_train)\n",
    "xgb.pred = xgb.predict(X_validation)\n",
    "print(\"Accuracy Score: \",accuracy_score(y_validation, xgb.pred))\n",
    "print(\"----------------------------------------------------------\")\n",
    "print(\"Confusion Matrix: \\n\",confusion_matrix(y_validation, xgb.pred))\n",
    "print(\"----------------------------------------------------------\")\n",
    "print(\"Classification Report: \\n\",classification_report(y_validation, xgb.pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Model Tuning: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting graphviz\n",
      "  Downloading https://files.pythonhosted.org/packages/5c/b1/016e657586843f40b4daa66127ce1ee9e3285ff15baf5d80946644a98aeb/graphviz-0.11.1-py2.py3-none-any.whl\n",
      "Installing collected packages: graphviz\n",
      "Successfully installed graphviz-0.11.1\n"
     ]
    }
   ],
   "source": [
    "!pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bynode=1, colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "       max_delta_step=0, max_depth=3, min_child_weight=1, missing=None,\n",
      "       n_estimators=100, n_jobs=1, nthread=None,\n",
      "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
      "       reg_lambda=1, scale_pos_weight=1, seed=123, silent=None,\n",
      "       subsample=1, verbosity=1)\n"
     ]
    }
   ],
   "source": [
    "from xgboost.sklearn import XGBClassifier\n",
    "from matplotlib.pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# fit model\n",
    "model = XGBClassifier(seed = 123)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# printing the model for visualization\n",
    "print(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([8.62590561, 8.55667553, 8.93888726]), 'std_fit_time': array([0.0833693 , 0.08577786, 0.05231938]), 'mean_score_time': array([0.04717612, 0.04813294, 0.04843526]), 'std_score_time': array([0.00137995, 0.00235028, 0.00165646]), 'param_objective': masked_array(data=['reg:linear', 'binary:logistic', 'count:poisson'],\n",
      "             mask=[False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'objective': 'reg:linear'}, {'objective': 'binary:logistic'}, {'objective': 'count:poisson'}], 'split0_test_score': array([0.94737647, 0.94696352, 0.94366305]), 'split1_test_score': array([0.94646082, 0.94452804, 0.94117797]), 'split2_test_score': array([0.94367012, 0.94108101, 0.93618121]), 'split3_test_score': array([0.94257027, 0.94156208, 0.93682814]), 'split4_test_score': array([0.94315275, 0.94360241, 0.93923457]), 'mean_test_score': array([0.94464633, 0.94354755, 0.93941718]), 'std_test_score': array([0.00190998, 0.00212889, 0.00276907]), 'rank_test_score': array([1, 2, 3]), 'split0_train_score': array([0.95025448, 0.94760537, 0.94235496]), 'split1_train_score': array([0.95141994, 0.94796935, 0.94241553]), 'split2_train_score': array([0.95192017, 0.94868187, 0.94341622]), 'split3_train_score': array([0.95131187, 0.94950949, 0.94369497]), 'split4_train_score': array([0.95113533, 0.94920742, 0.94321701]), 'mean_train_score': array([0.95120836, 0.9485947 , 0.94301974]), 'std_train_score': array([0.00054358, 0.00071968, 0.0005402 ])}\n",
      "----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Tune objective\n",
    "param_set0 = {\n",
    "    'objective': ('reg:linear', 'binary:logistic','count:poisson')\n",
    "}\n",
    "\n",
    "xgb0 = XGBClassifier(silent=True, nthread=-1, max_delta_step=0.7, seed=123)\n",
    "\n",
    "gsearch0 = GridSearchCV(estimator=xgb0, param_grid=param_set0, scoring='roc_auc', n_jobs=4, cv=5) #verbose=2\n",
    "gsearch0.fit(X_train, y_train)\n",
    "print(gsearch0.cv_results_)\n",
    "print(\"----------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([ 8.77396464,  8.43582973,  8.54549284,  8.70767937,  8.80262375,\n",
      "        8.69096794, 10.72759461, 10.36860304, 10.82988844, 10.77544198,\n",
      "       10.65311375, 10.88728647, 12.67296362, 12.65278068, 12.501085  ,\n",
      "       12.63317785, 12.20717812, 12.18108315, 14.58736987, 14.68252864,\n",
      "       14.42048559, 14.61298351, 14.58635678, 14.93660598, 16.85629539,\n",
      "       16.50744381, 16.55961342, 16.41415834, 16.61527066, 16.59930348,\n",
      "       19.06946168, 18.73354259, 18.72301974, 18.77359104, 18.54600077,\n",
      "       18.71179905, 21.20293922, 20.38028293, 20.09909878, 20.15960793,\n",
      "       19.94792137, 20.59962473]), 'std_fit_time': array([0.23477043, 0.05950487, 0.06206892, 0.08145983, 0.15728802,\n",
      "       0.24794555, 0.05363619, 0.20214987, 0.20123698, 0.14053032,\n",
      "       0.10105363, 0.34647702, 0.14961853, 0.08751632, 0.14140507,\n",
      "       0.13274506, 0.18392775, 0.08812771, 0.18908338, 0.05549451,\n",
      "       0.17275499, 0.12706477, 0.14948125, 0.27721488, 0.15791342,\n",
      "       0.31020043, 0.1595946 , 0.19441238, 0.09095503, 0.25904058,\n",
      "       0.22645816, 0.26510816, 0.18763902, 0.36598172, 0.28453223,\n",
      "       0.31412093, 0.26746165, 0.18832078, 0.11722168, 0.28986973,\n",
      "       0.23428666, 0.3200611 ]), 'mean_score_time': array([0.04924078, 0.04764581, 0.05166206, 0.05362263, 0.05320921,\n",
      "       0.05146465, 0.05921955, 0.05739269, 0.06017585, 0.0636095 ,\n",
      "       0.06083736, 0.06004238, 0.0718081 , 0.06597233, 0.06721172,\n",
      "       0.07376599, 0.06482673, 0.06540384, 0.06772947, 0.07519941,\n",
      "       0.07649913, 0.07395687, 0.0777142 , 0.07367859, 0.08796468,\n",
      "       0.08913822, 0.09015918, 0.0817802 , 0.08790255, 0.08794036,\n",
      "       0.0998054 , 0.10119605, 0.1072443 , 0.09757023, 0.09683704,\n",
      "       0.09674139, 0.10798354, 0.1058146 , 0.10539775, 0.10159731,\n",
      "       0.10611596, 0.11159844]), 'std_score_time': array([0.00558487, 0.00448108, 0.00171624, 0.00282418, 0.00578128,\n",
      "       0.00899303, 0.00761879, 0.00715894, 0.00133042, 0.00559731,\n",
      "       0.00166929, 0.00411131, 0.00857944, 0.00150248, 0.00176926,\n",
      "       0.00791876, 0.00339659, 0.00400231, 0.0129839 , 0.00272081,\n",
      "       0.00478851, 0.00579078, 0.00504863, 0.00194772, 0.00456646,\n",
      "       0.00395856, 0.00482885, 0.0089215 , 0.00106967, 0.00373812,\n",
      "       0.00294859, 0.00280992, 0.01534199, 0.00714709, 0.00280392,\n",
      "       0.00227479, 0.00859496, 0.00513985, 0.0039064 , 0.01300172,\n",
      "       0.00726359, 0.00584638]), 'param_max_depth': masked_array(data=[3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5,\n",
      "                   6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8,\n",
      "                   9, 9, 9, 9, 9, 9],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_min_child_weight': masked_array(data=[2, 3, 4, 5, 6, 7, 2, 3, 4, 5, 6, 7, 2, 3, 4, 5, 6, 7,\n",
      "                   2, 3, 4, 5, 6, 7, 2, 3, 4, 5, 6, 7, 2, 3, 4, 5, 6, 7,\n",
      "                   2, 3, 4, 5, 6, 7],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'max_depth': 3, 'min_child_weight': 2}, {'max_depth': 3, 'min_child_weight': 3}, {'max_depth': 3, 'min_child_weight': 4}, {'max_depth': 3, 'min_child_weight': 5}, {'max_depth': 3, 'min_child_weight': 6}, {'max_depth': 3, 'min_child_weight': 7}, {'max_depth': 4, 'min_child_weight': 2}, {'max_depth': 4, 'min_child_weight': 3}, {'max_depth': 4, 'min_child_weight': 4}, {'max_depth': 4, 'min_child_weight': 5}, {'max_depth': 4, 'min_child_weight': 6}, {'max_depth': 4, 'min_child_weight': 7}, {'max_depth': 5, 'min_child_weight': 2}, {'max_depth': 5, 'min_child_weight': 3}, {'max_depth': 5, 'min_child_weight': 4}, {'max_depth': 5, 'min_child_weight': 5}, {'max_depth': 5, 'min_child_weight': 6}, {'max_depth': 5, 'min_child_weight': 7}, {'max_depth': 6, 'min_child_weight': 2}, {'max_depth': 6, 'min_child_weight': 3}, {'max_depth': 6, 'min_child_weight': 4}, {'max_depth': 6, 'min_child_weight': 5}, {'max_depth': 6, 'min_child_weight': 6}, {'max_depth': 6, 'min_child_weight': 7}, {'max_depth': 7, 'min_child_weight': 2}, {'max_depth': 7, 'min_child_weight': 3}, {'max_depth': 7, 'min_child_weight': 4}, {'max_depth': 7, 'min_child_weight': 5}, {'max_depth': 7, 'min_child_weight': 6}, {'max_depth': 7, 'min_child_weight': 7}, {'max_depth': 8, 'min_child_weight': 2}, {'max_depth': 8, 'min_child_weight': 3}, {'max_depth': 8, 'min_child_weight': 4}, {'max_depth': 8, 'min_child_weight': 5}, {'max_depth': 8, 'min_child_weight': 6}, {'max_depth': 8, 'min_child_weight': 7}, {'max_depth': 9, 'min_child_weight': 2}, {'max_depth': 9, 'min_child_weight': 3}, {'max_depth': 9, 'min_child_weight': 4}, {'max_depth': 9, 'min_child_weight': 5}, {'max_depth': 9, 'min_child_weight': 6}, {'max_depth': 9, 'min_child_weight': 7}], 'split0_test_score': array([0.94742653, 0.94689301, 0.94718014, 0.94699163, 0.9471158 ,\n",
      "       0.94798004, 0.95066535, 0.95018175, 0.950207  , 0.95049413,\n",
      "       0.94979676, 0.95072443, 0.95038123, 0.9512802 , 0.95046963,\n",
      "       0.94985809, 0.95108447, 0.95169811, 0.95136318, 0.95063168,\n",
      "       0.95077329, 0.95078532, 0.94845102, 0.95066175, 0.95019979,\n",
      "       0.94947686, 0.95054765, 0.94855985, 0.95038018, 0.94976203,\n",
      "       0.94674374, 0.94938756, 0.94699328, 0.94800048, 0.94701763,\n",
      "       0.94900843, 0.9428379 , 0.94368335, 0.94476   , 0.94367929,\n",
      "       0.94563611, 0.94308985]), 'split1_test_score': array([0.94623367, 0.94665534, 0.94667534, 0.94620451, 0.94622089,\n",
      "       0.94591242, 0.94830399, 0.94956705, 0.94956089, 0.95000661,\n",
      "       0.95022444, 0.94958239, 0.95120188, 0.95095759, 0.94963921,\n",
      "       0.94968536, 0.94945596, 0.95007982, 0.95044693, 0.95064446,\n",
      "       0.95082079, 0.9511446 , 0.95062206, 0.95090919, 0.95022008,\n",
      "       0.94936591, 0.94859698, 0.95010658, 0.95010373, 0.9507312 ,\n",
      "       0.94770494, 0.94626058, 0.94660152, 0.94901264, 0.94685393,\n",
      "       0.946249  , 0.94266773, 0.9413746 , 0.94280272, 0.9444834 ,\n",
      "       0.9444371 , 0.9408465 ]), 'split2_test_score': array([0.94365794, 0.94380045, 0.94381955, 0.94383774, 0.94423039,\n",
      "       0.94408457, 0.94601359, 0.94578193, 0.94618917, 0.94637708,\n",
      "       0.94582673, 0.94580358, 0.94657988, 0.94717563, 0.94565881,\n",
      "       0.94629621, 0.94600998, 0.94724448, 0.94527367, 0.9445521 ,\n",
      "       0.94317885, 0.94394402, 0.94359811, 0.9450572 , 0.94313736,\n",
      "       0.94138453, 0.94278965, 0.94289052, 0.94197877, 0.94152448,\n",
      "       0.94071436, 0.9398175 , 0.93686144, 0.93978187, 0.94053818,\n",
      "       0.94034696, 0.93290871, 0.93578419, 0.93561612, 0.93586116,\n",
      "       0.93585845, 0.93650877]), 'split3_test_score': array([0.94216489, 0.94215224, 0.94261816, 0.94269105, 0.94282567,\n",
      "       0.94235553, 0.94595131, 0.94569742, 0.9456429 , 0.94517668,\n",
      "       0.94425055, 0.94477686, 0.94569275, 0.94690846, 0.94661496,\n",
      "       0.94637914, 0.94615476, 0.94547394, 0.94671179, 0.94480532,\n",
      "       0.947264  , 0.9464847 , 0.94499236, 0.94570841, 0.94520936,\n",
      "       0.94619286, 0.94524625, 0.94617599, 0.94549954, 0.94563989,\n",
      "       0.94078067, 0.94106558, 0.94405087, 0.94149898, 0.94312685,\n",
      "       0.94187244, 0.94105128, 0.93993315, 0.93699726, 0.94193509,\n",
      "       0.94222844, 0.94207182]), 'split4_test_score': array([0.94321299, 0.94296196, 0.94342909, 0.94319326, 0.94285444,\n",
      "       0.94276167, 0.94529248, 0.94612509, 0.94457101, 0.94568356,\n",
      "       0.94526748, 0.94559848, 0.94502669, 0.9458465 , 0.94645232,\n",
      "       0.94532094, 0.94712365, 0.94568703, 0.94473485, 0.94186145,\n",
      "       0.94641076, 0.94571684, 0.94609979, 0.946435  , 0.94635384,\n",
      "       0.94422766, 0.94434618, 0.94447433, 0.94325244, 0.94552861,\n",
      "       0.94161373, 0.94213507, 0.94082675, 0.94457071, 0.94239529,\n",
      "       0.93698762, 0.93977368, 0.93973799, 0.93895522, 0.93923562,\n",
      "       0.93656762, 0.94045901]), 'mean_test_score': array([0.9445392 , 0.9444926 , 0.94474445, 0.94458364, 0.94464944,\n",
      "       0.94461885, 0.94724535, 0.94747065, 0.9472342 , 0.94754761,\n",
      "       0.94707319, 0.94729715, 0.94777648, 0.94843368, 0.94776699,\n",
      "       0.94750795, 0.94796576, 0.94803668, 0.94770608, 0.946499  ,\n",
      "       0.94768954, 0.9476151 , 0.94675267, 0.94775431, 0.94702408,\n",
      "       0.94612956, 0.94630534, 0.94644145, 0.94624293, 0.94663724,\n",
      "       0.94351149, 0.94373326, 0.94306677, 0.94457294, 0.94398638,\n",
      "       0.94289289, 0.93984786, 0.94010266, 0.93982626, 0.94103891,\n",
      "       0.94094554, 0.94059519]), 'std_test_score': array([0.00196879, 0.00193591, 0.00183126, 0.00170276, 0.00174792,\n",
      "       0.0020894 , 0.00199111, 0.00197745, 0.00223463, 0.00224476,\n",
      "       0.00245478, 0.00238481, 0.00252401, 0.00223943, 0.0019136 ,\n",
      "       0.00188626, 0.00198801, 0.00246157, 0.00270629, 0.00353355,\n",
      "       0.00288017, 0.00285887, 0.00250331, 0.00251424, 0.00279816,\n",
      "       0.00309241, 0.00284847, 0.00262564, 0.00345547, 0.00331327,\n",
      "       0.00306318, 0.00355984, 0.00380537, 0.00357386, 0.00255232,\n",
      "       0.00426752, 0.00364685, 0.00257876, 0.00345509, 0.00315278,\n",
      "       0.00402201, 0.00224429]), 'rank_test_score': array([30, 31, 25, 28, 26, 27, 14, 12, 15, 10, 16, 13,  4,  1,  5, 11,  3,\n",
      "        2,  7, 20,  8,  9, 18,  6, 17, 24, 22, 21, 23, 19, 34, 33, 35, 29,\n",
      "       32, 36, 41, 40, 42, 37, 38, 39]), 'split0_train_score': array([0.95018767, 0.95001992, 0.9502344 , 0.95035478, 0.95040335,\n",
      "       0.95049328, 0.95876246, 0.95839219, 0.95846572, 0.95814201,\n",
      "       0.95800942, 0.9584393 , 0.96532584, 0.96522055, 0.96508936,\n",
      "       0.96530026, 0.96566189, 0.96530376, 0.9743932 , 0.97338287,\n",
      "       0.97387635, 0.97203611, 0.97234257, 0.97248764, 0.98295283,\n",
      "       0.98180478, 0.98165215, 0.98131737, 0.98087588, 0.97969819,\n",
      "       0.99116307, 0.98949905, 0.98823763, 0.98801432, 0.98714209,\n",
      "       0.98706419, 0.99562402, 0.99515706, 0.99299413, 0.9933641 ,\n",
      "       0.99276984, 0.99189154]), 'split1_train_score': array([0.95078665, 0.95149872, 0.9512799 , 0.95064039, 0.95104601,\n",
      "       0.95044884, 0.95938658, 0.95951287, 0.95926883, 0.95940525,\n",
      "       0.95910833, 0.9588539 , 0.9674807 , 0.96654577, 0.96575152,\n",
      "       0.96646911, 0.96558573, 0.96512872, 0.97391438, 0.97487955,\n",
      "       0.9741776 , 0.97339929, 0.97313489, 0.97268658, 0.9830468 ,\n",
      "       0.98266618, 0.98179246, 0.9819697 , 0.98001535, 0.98021879,\n",
      "       0.99011525, 0.9902772 , 0.98819205, 0.98823487, 0.98686275,\n",
      "       0.98575051, 0.99543211, 0.99505112, 0.99419317, 0.99278227,\n",
      "       0.9923307 , 0.99072609]), 'split2_train_score': array([0.95174993, 0.95179289, 0.95171735, 0.95163441, 0.95181954,\n",
      "       0.95172269, 0.95890495, 0.95853908, 0.95865222, 0.9589408 ,\n",
      "       0.95883397, 0.95851894, 0.96648043, 0.96615939, 0.9669782 ,\n",
      "       0.9663865 , 0.96707164, 0.96627886, 0.97567921, 0.97466957,\n",
      "       0.97552521, 0.97534234, 0.97512243, 0.97469083, 0.98547361,\n",
      "       0.98487836, 0.98498511, 0.98465241, 0.98397572, 0.98242441,\n",
      "       0.99292507, 0.99117247, 0.99103572, 0.99032782, 0.98902621,\n",
      "       0.98839533, 0.99677635, 0.99565212, 0.99625289, 0.99475268,\n",
      "       0.99439469, 0.99276109]), 'split3_train_score': array([0.95129586, 0.95148661, 0.95135959, 0.95149227, 0.95163955,\n",
      "       0.95137136, 0.95850519, 0.95791517, 0.95857336, 0.95876894,\n",
      "       0.95827313, 0.95754216, 0.96590428, 0.96650397, 0.96603975,\n",
      "       0.96595324, 0.96556552, 0.96571199, 0.9743783 , 0.9742532 ,\n",
      "       0.97453372, 0.97372829, 0.97380801, 0.97339318, 0.98249215,\n",
      "       0.9828726 , 0.9824293 , 0.98194411, 0.98095119, 0.98050157,\n",
      "       0.99100322, 0.98937321, 0.98940675, 0.98848551, 0.98732302,\n",
      "       0.98714944, 0.99551816, 0.9945476 , 0.99430298, 0.99352192,\n",
      "       0.9917627 , 0.99141903]), 'split4_train_score': array([0.95099598, 0.95122471, 0.95169733, 0.95152352, 0.95129507,\n",
      "       0.9512123 , 0.95904437, 0.95945475, 0.95958196, 0.95969024,\n",
      "       0.95998655, 0.9597257 , 0.96732499, 0.96736124, 0.96593357,\n",
      "       0.96687957, 0.9666242 , 0.96713222, 0.97603012, 0.97584003,\n",
      "       0.97596069, 0.9750504 , 0.97354668, 0.97372758, 0.98421685,\n",
      "       0.98303773, 0.98219549, 0.98248171, 0.98114166, 0.98180758,\n",
      "       0.99127449, 0.98970529, 0.98906147, 0.98821293, 0.98791996,\n",
      "       0.98699855, 0.99560835, 0.9952223 , 0.99378392, 0.99318328,\n",
      "       0.99250889, 0.99208356]), 'mean_train_score': array([0.95100322, 0.95120457, 0.95125772, 0.95112908, 0.9512407 ,\n",
      "       0.95104969, 0.95892071, 0.95876281, 0.95890842, 0.95898945,\n",
      "       0.95884228, 0.958616  , 0.96650325, 0.96635818, 0.96595848,\n",
      "       0.96619773, 0.9661018 , 0.96591111, 0.97487904, 0.97460504,\n",
      "       0.97481471, 0.97391128, 0.97359092, 0.97339716, 0.98363645,\n",
      "       0.98305193, 0.9826109 , 0.98247306, 0.98139196, 0.98093011,\n",
      "       0.99129622, 0.99000544, 0.98918672, 0.98865509, 0.9876548 ,\n",
      "       0.9870716 , 0.9957918 , 0.99512604, 0.99430542, 0.99352085,\n",
      "       0.99275336, 0.99177626]), 'std_train_score': array([0.00052063, 0.00061903, 0.00054084, 0.00052559, 0.00049722,\n",
      "       0.00050069, 0.00029335, 0.00062406, 0.00043759, 0.00053538,\n",
      "       0.0006925 , 0.00070453, 0.00082174, 0.00069228, 0.0006075 ,\n",
      "       0.00053655, 0.00062625, 0.0007276 , 0.00082251, 0.00080277,\n",
      "       0.00079793, 0.00119644, 0.00091224, 0.00078929, 0.00108041,\n",
      "       0.00100722, 0.00121914, 0.00115052, 0.00134864, 0.0010208 ,\n",
      "       0.00091125, 0.00066061, 0.00103663, 0.00084964, 0.00076829,\n",
      "       0.00083773, 0.00049707, 0.00035417, 0.00107673, 0.00066354,\n",
      "       0.00088477, 0.00067943])}\n",
      "----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Tune max_depth and min_child_weight\n",
    "\n",
    "param_test1 = {\n",
    "    'max_depth': [3,4,5,6,7,8,9],\n",
    "    'min_child_weight': [2,3,4,5,6,7]\n",
    "}\n",
    "\n",
    "xgb1 = XGBClassifier(silent=True, nthread=-1, max_delta_step=0.7, seed=0, objective='reg:linear')\n",
    "gsearch1 = GridSearchCV(estimator = xgb1, param_grid = param_test1, scoring = 'roc_auc', n_jobs = 4, \n",
    "                        iid = False, cv = 5)\n",
    "gsearch1.fit(X_train,y_train)\n",
    "\n",
    "print(gsearch1.cv_results_)\n",
    "print(\"----------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([12.24665637, 12.09508066, 12.28616142, 12.67343893, 12.47232723,\n",
      "       12.54844108, 12.17669902, 11.98130703, 12.50352287]), 'std_fit_time': array([0.1747041 , 0.17763301, 0.24520567, 0.12546382, 0.15124505,\n",
      "       0.33984289, 0.31888892, 0.24120873, 0.1561917 ]), 'mean_score_time': array([0.06376314, 0.05993171, 0.06274967, 0.0596704 , 0.05405402,\n",
      "       0.04772973, 0.05177107, 0.04310808, 0.04654903]), 'std_score_time': array([0.00362494, 0.00773095, 0.00661086, 0.00317198, 0.00626505,\n",
      "       0.00578767, 0.00929887, 0.00404828, 0.00141067]), 'param_gamma': masked_array(data=[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'gamma': 0.1}, {'gamma': 0.2}, {'gamma': 0.3}, {'gamma': 0.4}, {'gamma': 0.5}, {'gamma': 0.6}, {'gamma': 0.7}, {'gamma': 0.8}, {'gamma': 0.9}], 'split0_test_score': array([0.95142181, 0.95119436, 0.95071827, 0.95161588, 0.95015845,\n",
      "       0.95042227, 0.95130034, 0.95090558, 0.94989793]), 'split1_test_score': array([0.9508707 , 0.95066175, 0.95057666, 0.95049233, 0.9497037 ,\n",
      "       0.95072579, 0.9498865 , 0.94960494, 0.9480767 ]), 'split2_test_score': array([0.94778296, 0.94522963, 0.94567099, 0.9467048 , 0.94661881,\n",
      "       0.94632011, 0.94632026, 0.94642639, 0.94645871]), 'split3_test_score': array([0.94577753, 0.94631318, 0.94517879, 0.94680259, 0.94673648,\n",
      "       0.94651467, 0.94460745, 0.94637115, 0.9460254 ]), 'split4_test_score': array([0.946919  , 0.94507548, 0.94465669, 0.94431094, 0.94597601,\n",
      "       0.94694942, 0.94617433, 0.94622599, 0.94625565]), 'mean_test_score': array([0.9485544 , 0.94769488, 0.94736028, 0.94798531, 0.94783869,\n",
      "       0.94818645, 0.94765778, 0.94790681, 0.94734288]), 'std_test_score': array([0.00221666, 0.00267942, 0.00270345, 0.00268349, 0.0017339 ,\n",
      "       0.00196242, 0.00251116, 0.00196221, 0.0014674 ]), 'rank_test_score': array([1, 6, 8, 3, 5, 2, 7, 4, 9]), 'split0_train_score': array([0.96545043, 0.96262137, 0.96503776, 0.96266846, 0.96171758,\n",
      "       0.95772293, 0.9591331 , 0.95613507, 0.95491421]), 'split1_train_score': array([0.96695767, 0.96600342, 0.96471315, 0.96591376, 0.96077186,\n",
      "       0.96159918, 0.96029177, 0.9584028 , 0.95654151]), 'split2_train_score': array([0.96597676, 0.96581714, 0.96183156, 0.96466725, 0.96115173,\n",
      "       0.96026113, 0.95997586, 0.95784547, 0.95769411]), 'split3_train_score': array([0.9666592 , 0.96578876, 0.96467323, 0.96212476, 0.96184128,\n",
      "       0.95975587, 0.95661383, 0.95819828, 0.95774743]), 'split4_train_score': array([0.96687529, 0.96615458, 0.9663333 , 0.96566209, 0.9648143 ,\n",
      "       0.96038903, 0.96075116, 0.95929885, 0.9586249 ]), 'mean_train_score': array([0.96638387, 0.96527706, 0.9645178 , 0.96420726, 0.96205935,\n",
      "       0.95994563, 0.95935314, 0.95797609, 0.95710443]), 'std_train_score': array([0.00058028, 0.00133445, 0.00147273, 0.00154564, 0.00143077,\n",
      "       0.00126545, 0.00146803, 0.00103803, 0.0012796 ])}\n"
     ]
    }
   ],
   "source": [
    "# Tune gamma\n",
    "param_test2 = {\n",
    "    'gamma':[i/10.0 for i in range(1,10,1)]\n",
    "}\n",
    "\n",
    "xgb2 = XGBClassifier(silent=True, nthread=-1, max_delta_step=0.7, seed=0, objective='reg:linear', \n",
    "                     max_depth=5, min_child_weight=3)\n",
    "gsearch2 = GridSearchCV(estimator = xgb2, param_grid = param_test2, scoring = 'roc_auc',n_jobs = 4,\n",
    "                         iid = False, cv = 5)\n",
    "gsearch2.fit(X_train,y_train)\n",
    "\n",
    "print(gsearch2.cv_results_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([12.37449393, 12.66350369, 12.58030443, 12.71971736, 12.63979979,\n",
      "       12.79279323, 12.63089828, 12.42377672, 12.4688179 ]), 'std_fit_time': array([0.11964427, 0.15060246, 0.27050999, 0.15161942, 0.05201932,\n",
      "       0.04178882, 0.21803865, 0.12791511, 0.17208523]), 'mean_score_time': array([0.06470909, 0.0671042 , 0.06862907, 0.06887889, 0.07041287,\n",
      "       0.06961455, 0.06844511, 0.07281556, 0.06924682]), 'std_score_time': array([0.01016616, 0.0074584 , 0.00205152, 0.00215981, 0.00135367,\n",
      "       0.00203435, 0.00242428, 0.00390691, 0.00348482]), 'param_reg_alpha': masked_array(data=[0, 0, 0, 2, 2, 2, 4, 4, 4],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_reg_lambda': masked_array(data=[1, 3, 5, 1, 3, 5, 1, 3, 5],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'reg_alpha': 0, 'reg_lambda': 1}, {'reg_alpha': 0, 'reg_lambda': 3}, {'reg_alpha': 0, 'reg_lambda': 5}, {'reg_alpha': 2, 'reg_lambda': 1}, {'reg_alpha': 2, 'reg_lambda': 3}, {'reg_alpha': 2, 'reg_lambda': 5}, {'reg_alpha': 4, 'reg_lambda': 1}, {'reg_alpha': 4, 'reg_lambda': 3}, {'reg_alpha': 4, 'reg_lambda': 5}], 'split0_test_score': array([0.95142181, 0.94976023, 0.9499791 , 0.95099202, 0.95058974,\n",
      "       0.95154252, 0.95254491, 0.95186588, 0.95144601]), 'split1_test_score': array([0.9508707 , 0.94912208, 0.94943131, 0.95119767, 0.95093805,\n",
      "       0.950687  , 0.949655  , 0.94999775, 0.94923378]), 'split2_test_score': array([0.94778296, 0.94660919, 0.94592144, 0.94639422, 0.94571549,\n",
      "       0.94613085, 0.94607703, 0.94591963, 0.94621518]), 'split3_test_score': array([0.94577753, 0.94673121, 0.94666435, 0.94642672, 0.94723463,\n",
      "       0.94762933, 0.94774739, 0.94760523, 0.94735676]), 'split4_test_score': array([0.946919  , 0.94627929, 0.94731189, 0.94678904, 0.9473271 ,\n",
      "       0.947456  , 0.94699625, 0.9467672 , 0.94740088]), 'mean_test_score': array([0.9485544 , 0.9477004 , 0.94786162, 0.94835993, 0.948361  ,\n",
      "       0.94868914, 0.94860412, 0.94843114, 0.94833052]), 'std_test_score': array([0.00221666, 0.00144317, 0.00157782, 0.00223829, 0.0020467 ,\n",
      "       0.00206504, 0.00229519, 0.00219135, 0.00183353]), 'rank_test_score': array([3, 9, 8, 6, 5, 1, 2, 4, 7]), 'split0_train_score': array([0.96545043, 0.9638215 , 0.96355533, 0.96411504, 0.96407423,\n",
      "       0.96353019, 0.9622041 , 0.9614586 , 0.96174961]), 'split1_train_score': array([0.96695767, 0.96553146, 0.96454348, 0.96523021, 0.96481921,\n",
      "       0.96444174, 0.96230039, 0.96254835, 0.9622516 ]), 'split2_train_score': array([0.96597676, 0.96520227, 0.96410886, 0.96599193, 0.96576847,\n",
      "       0.96537633, 0.96377929, 0.96320007, 0.96343146]), 'split3_train_score': array([0.9666592 , 0.96526486, 0.96458881, 0.96472488, 0.96466654,\n",
      "       0.96428272, 0.96259934, 0.96264298, 0.96259413]), 'split4_train_score': array([0.96687529, 0.96584394, 0.96511995, 0.96572468, 0.9653458 ,\n",
      "       0.96441022, 0.96284759, 0.96297397, 0.96244998]), 'mean_train_score': array([0.96638387, 0.96513281, 0.96438328, 0.96515735, 0.96493485,\n",
      "       0.96440824, 0.96274614, 0.96256479, 0.96249536]), 'std_train_score': array([0.00058028, 0.00069375, 0.00052372, 0.00067781, 0.00058135,\n",
      "       0.00058738, 0.00056422, 0.00060018, 0.00054839])}\n"
     ]
    }
   ],
   "source": [
    "# Tune reg_alpha and reg_lambda\n",
    "param_test3 = {\n",
    "    'reg_alpha': (0,2,4),\n",
    "    'reg_lambda': (1,3,5)\n",
    "}\n",
    "\n",
    "xgb3 = XGBClassifier(silent=True, nthread=-1, max_delta_step=0.7, seed=0, objective='reg:linear', \n",
    "                     max_depth=5, min_child_weight=3, gamma=0.1)\n",
    "gsearch3 = GridSearchCV(estimator = xgb3, param_grid = param_test3, scoring = 'roc_auc',n_jobs = 4,\n",
    "                         iid = False, cv = 5)\n",
    "gsearch3.fit(X_train,y_train)\n",
    "\n",
    "print(gsearch3.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([ 7.44289103,  6.45656071,  9.96764674,  8.11350517,  9.13836932,\n",
      "        7.78580518, 16.43004804, 14.03326221]), 'std_fit_time': array([0.09864985, 0.14621803, 0.15605082, 0.1449472 , 0.14838586,\n",
      "       0.14543749, 0.99849858, 0.63955741]), 'mean_score_time': array([0.07026501, 0.06958675, 0.06672072, 0.06753035, 0.06517291,\n",
      "       0.07361674, 0.07705169, 0.07704139]), 'std_score_time': array([0.0037472 , 0.00372233, 0.00356785, 0.00620985, 0.00553672,\n",
      "       0.01010769, 0.00322709, 0.00561406]), 'param_colsample_bylevel': masked_array(data=[0.5, 0.5, 0.5, 0.5, 1, 1, 1, 1],\n",
      "             mask=[False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_colsample_bytree': masked_array(data=[0.5, 0.5, 1, 1, 0.5, 0.5, 1, 1],\n",
      "             mask=[False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_subsample': masked_array(data=[0.5, 1, 0.5, 1, 0.5, 1, 0.5, 1],\n",
      "             mask=[False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'colsample_bylevel': 0.5, 'colsample_bytree': 0.5, 'subsample': 0.5}, {'colsample_bylevel': 0.5, 'colsample_bytree': 0.5, 'subsample': 1}, {'colsample_bylevel': 0.5, 'colsample_bytree': 1, 'subsample': 0.5}, {'colsample_bylevel': 0.5, 'colsample_bytree': 1, 'subsample': 1}, {'colsample_bylevel': 1, 'colsample_bytree': 0.5, 'subsample': 0.5}, {'colsample_bylevel': 1, 'colsample_bytree': 0.5, 'subsample': 1}, {'colsample_bylevel': 1, 'colsample_bytree': 1, 'subsample': 0.5}, {'colsample_bylevel': 1, 'colsample_bytree': 1, 'subsample': 1}], 'split0_test_score': array([0.95005908, 0.95035087, 0.95096075, 0.95104553, 0.95092061,\n",
      "       0.95044678, 0.95017303, 0.95154252]), 'split1_test_score': array([0.94774071, 0.94978247, 0.94990394, 0.95087822, 0.94791254,\n",
      "       0.94926895, 0.94802228, 0.950687  ]), 'split2_test_score': array([0.94399814, 0.94505976, 0.94310849, 0.94646683, 0.94485275,\n",
      "       0.94442131, 0.94400144, 0.94613085]), 'split3_test_score': array([0.94414243, 0.94499582, 0.9450812 , 0.94649524, 0.94284344,\n",
      "       0.94398401, 0.94366265, 0.94762933]), 'split4_test_score': array([0.94458742, 0.94609317, 0.94648078, 0.94702547, 0.94287687,\n",
      "       0.94699926, 0.94610853, 0.947456  ]), 'mean_test_score': array([0.94610556, 0.94725642, 0.94710703, 0.94838226, 0.94588124,\n",
      "       0.94702406, 0.94639359, 0.94868914]), 'std_test_score': array([0.00240433, 0.00233432, 0.00293797, 0.00211629, 0.00312518,\n",
      "       0.00256013, 0.00245758, 0.00206504]), 'rank_test_score': array([7, 3, 4, 2, 8, 5, 6, 1]), 'split0_train_score': array([0.95543457, 0.95759667, 0.95875059, 0.96123699, 0.95834686,\n",
      "       0.95937304, 0.96042645, 0.96353019]), 'split1_train_score': array([0.95599325, 0.95752281, 0.95986167, 0.96209181, 0.95930937,\n",
      "       0.96029272, 0.96179598, 0.96444174]), 'split2_train_score': array([0.95710821, 0.95918009, 0.95954092, 0.96321344, 0.95955533,\n",
      "       0.96126786, 0.96316337, 0.96537633]), 'split3_train_score': array([0.95669715, 0.95943504, 0.95943084, 0.96256716, 0.95938449,\n",
      "       0.95998783, 0.96259291, 0.96428272]), 'split4_train_score': array([0.95688317, 0.95885179, 0.96070965, 0.96281612, 0.95837913,\n",
      "       0.96104285, 0.96232975, 0.96441022]), 'mean_train_score': array([0.95642327, 0.95851728, 0.95965873, 0.9623851 , 0.95899504,\n",
      "       0.96039286, 0.96206169, 0.96440824]), 'std_train_score': array([0.00061937, 0.00080374, 0.00063814, 0.00067959, 0.00052228,\n",
      "       0.00069314, 0.00092869, 0.00058738])}\n"
     ]
    }
   ],
   "source": [
    "# Tune subsample, colsample_bytree and colsample_bylevel\n",
    "param_test4 = {\n",
    "    'subsample': (0.5, 1),\n",
    "    'colsample_bytree': (0.5, 1),\n",
    "    'colsample_bylevel': (0.5, 1)\n",
    "}\n",
    "\n",
    "xgb4 = XGBClassifier(silent=True, nthread=-1, max_delta_step=0.7, seed=0, objective='reg:linear', \n",
    "                     max_depth=5, min_child_weight=3, gamma=0.1, reg_alpha=2, reg_lambda=5)\n",
    "gsearch4 = GridSearchCV(estimator = xgb4, param_grid = param_test4, scoring = 'roc_auc',n_jobs = 4,\n",
    "                         iid = False, cv = 5)\n",
    "gsearch4.fit(X_train,y_train)\n",
    "\n",
    "print(gsearch4.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions on the validation set based on tuned model:\n",
    "\n",
    "The XGB model was the most accurate model that we tested. Now we want to get an idea of accuracy of the model on our validation set. This will give us an independent final check on the accuracy of th best model.\n",
    "\n",
    "We can run the XGB model directly on the validation set and summarize the results as a final accuracy score, a confusion matrix and a classification report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.9202880958161366\n",
      "----------------------------------------------------------\n",
      "Confusion Matrix: \n",
      " [[10615   350]\n",
      " [  635   757]]\n",
      "----------------------------------------------------------\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96     10965\n",
      "           1       0.68      0.54      0.61      1392\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     12357\n",
      "   macro avg       0.81      0.76      0.78     12357\n",
      "weighted avg       0.91      0.92      0.92     12357\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select best model\n",
    "# Make predictions on validation dataset using tuned parameters\n",
    "tuned_model = XGBClassifier(silent=True, nthread=-1, max_delta_step=0.7, seed=0, objective='reg:linear', \n",
    "                     max_depth=5, min_child_weight=3, gamma=0.1, reg_alpha=2, reg_lambda=5, subsample=1, \n",
    "                            colsample_bytree=1, colsample_bylevel=1)\n",
    "tuned_fit = tuned_model.fit(X_train, y_train)\n",
    "tuned_pred = tuned_model.predict(X_validation)\n",
    "\n",
    "print(\"Accuracy Score: \",accuracy_score(y_validation, tuned_pred))\n",
    "print(\"----------------------------------------------------------\")\n",
    "print(\"Confusion Matrix: \\n\",confusion_matrix(y_validation, tuned_pred))\n",
    "print(\"----------------------------------------------------------\")\n",
    "print(\"Classification Report: \\n\",classification_report(y_validation, tuned_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
